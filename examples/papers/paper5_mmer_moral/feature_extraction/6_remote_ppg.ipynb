{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remote PPG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from importlib import import_module, util\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pyVHR.extraction.sig_processing import *\n",
    "from pyVHR.extraction.sig_extraction_methods import *\n",
    "from pyVHR.extraction.skin_extraction_methods import *\n",
    "from pyVHR.BVP.BVP import *\n",
    "from pyVHR.BPM.BPM import *\n",
    "from pyVHR.BVP.methods import *\n",
    "from pyVHR.plot.visualize import visualize_landmarks_list\n",
    "import shutil\n",
    "import csv\n",
    "import time\n",
    "from datetime import datetime\n",
    "import plotly.express as px\n",
    "from inspect import getmembers, isfunction\n",
    "\n",
    "# Get the parent directory\n",
    "# This is useful if you need to import modules from a parent directory.\n",
    "import sys\n",
    "parent_dir = os.path.abspath('../')\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Import any custom utilities from the parent directory (if needed)\n",
    "import utilities\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = os.path.abspath(\"../../../\")\n",
    "if str(project_path) not in sys.path:\n",
    "    sys.path.insert(0, str(project_path))\n",
    "    print(f\"Added {project_path} to sys.path\")\n",
    "else:\n",
    "    print(f\"{project_path} is already in sys.path\")\n",
    "\n",
    "from psychai_v1.remote_ppg.vhr.filters import *\n",
    "from psychai_v1.remote_ppg.vhr.signal_process import SignalProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_approach=\"patches\"\n",
    "roi_method=\"faceparsing\"\n",
    "cuda=True\n",
    "method='cupy_POS'\n",
    "bpm_type='welch'\n",
    "pre_filt=False\n",
    "post_filt=True\n",
    "verb=True\n",
    "\n",
    "to_recalculate = False #是否重新建計算而不要用舊的結果\n",
    "debug_mode = False\n",
    "length_of_windows = 12\n",
    "\n",
    "\n",
    "\n",
    "input_path =  r'D:\\Programming3\\psychai\\example\\paper5_mmer_moral\\results\\remote_ppg'\n",
    "target_file_path =  r'D:\\Programming3\\psychai\\example\\paper5_mmer_moral\\results\\remote_ppg\\finished_video'\n",
    "image_output_path = r'D:\\Programming3\\psychai\\example\\paper5_mmer_moral\\results\\remote_ppg\\image_output'\n",
    "sig_output_path = r'D:\\Programming3\\psychai\\example\\paper5_mmer_moral\\results\\remote_ppg\\sig_output'\n",
    "bvps_output_path = r'D:\\Programming3\\psychai\\example\\paper5_mmer_moral\\results\\remote_ppg\\bvps_results'\n",
    "bpmES_output_path = r'D:\\Programming3\\psychai\\example\\paper5_mmer_moral\\results\\remote_ppg\\bpmES_results'\n",
    "bpm_output_path = r'D:\\Programming3\\psychai\\example\\paper5_mmer_moral\\results\\remote_ppg\\bpm_results'\n",
    "file_name = r'D:\\Programming3\\psychai\\example\\paper5_mmer_moral\\resources\\images\\face_example.jpg' #測試用\n",
    "testing_video_file = r'D:\\Programming3\\psychai\\example\\paper5_mmer_moral\\resources\\videos\\thermal_participant_1.mp4'\n",
    "extension = \"mp4\"\n",
    "\n",
    "do_image_extraction = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#100个特征点\n",
    "# 所有特征点的定义可以参考:\n",
    "\n",
    "# https://google.github.io/mediapipe/solutions/face_mesh.html\n",
    "# https://raw.githubusercontent.com/google/mediapipe/a908d668c730da128dfa8d9f6bd25d519d006692/mediapipe/modules/face_geometry/data/canonical_face_model_uv_visualization.png\n",
    "# https://github.com/tensorflow/tfjs-models/blob/838611c02f51159afdd77469ce67f0e26b7bbb23/face-landmarks-detection/src/mediapipe-facemesh/keypoints.ts\n",
    "\n",
    "landmarks_list = [3, 4, 5, 6, 8, 9, 10, 18, 32, 36, 43, 48, 50, 67, 69, 92, 101, 103, 104, 108, 109, 123, 134, 135, 142, 151, 164, 167, 182, 187, 192, 197, 201, 205, 206, 207, 210, 211, 212, 216, 248, 262, 266, 273, 278, 280, 297, 299, 322, 330, 332, 333, 337, 338, 352,  363, 364, 371, 393, 406, 411, 416, 421, 425, 426, 427, 430,431, 432, 436]\n",
    "ldmks_list_A = [2, 3, 4, 5, 6, 8, 9, 10, 18, 21, 32, 35, 36, 43, 46, 47, 48, 50, 54, 58, 67, 68, 69, 71, 92, 93, 101, 103, 104, 108, 109, 116, 117, 118, 123, 132, 134, 135, 138, 139, 142, 148, 149, 150, 151, 152, 182, 187, 188, 193, 197, 201, 205, 206, 207, 210, 211, 212, 216, 234, 248, 251, 262, 265, 266, 273, 277, 278, 280, 284, 288, 297, 299, 322, 323, 330, 332, 333, 337, 338, 345, 346, 361, 363, 364, 367, 368, 371, 377, 379, 411, 412, 417, 421, 425, 426, 427, 430, 432, 436]\n",
    "ldmks_list_C = [2]\n",
    "ldmks_list_B = [3, 4, 5, 6, 8, 9, 10, 18, 32, 36, 43, 48, 50, 67, 69, 92, 101, 103, 104, 108, 109, 123, 134, 135, 142, 151, 164, 167, 182, 187, 192, 197, 201, 205, 206, 207, 210, 211, 212, 216, 248, 262, 266, 273, 278, 280, 297, 299, 322, 330, 332, 333, 337, 338, 352,  363, 364, 371, 393, 406, 411, 416, 421, 425, 426, 427, 430,431, 432, 436]\n",
    "ldmks_list_choice = \"B\"\n",
    "ldmks_list = ldmks_list_B\n",
    "\n",
    "sig_processing = SignalProcessing()\n",
    "av_meths = getmembers(pyVHR.BVP.methods, isfunction)\n",
    "available_methods = [am[0] for am in av_meths]\n",
    "assert method in available_methods, \"\\nrPPG method not recognized!!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sig_processing = SignalProcessing()\n",
    "# av_meths = getmembers(pyVHR.BVP.methods, isfunction)\n",
    "# available_methods = [am[0] for am in av_meths]\n",
    "\n",
    "\n",
    "\n",
    "#檢查landmark點用\n",
    "PRESENCE_THRESHOLD = 0.5\n",
    "VISIBILITY_THRESHOLD = 0.5\n",
    "\n",
    "if do_image_extraction:\n",
    "\n",
    "    imag = cv2.imread(file_name, cv2.COLOR_RGB2BGR)\n",
    "    imag = cv2.cvtColor(imag, cv2.COLOR_BGR2RGB)\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    with mp_face_mesh.FaceMesh(\n",
    "            static_image_mode=True,\n",
    "            max_num_faces=1,\n",
    "            min_detection_confidence=0.5) as face_mesh:\n",
    "        image = cv2.imread(file_name)\n",
    "        results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        width = image.shape[1]\n",
    "        height = image.shape[0]\n",
    "        face_landmarks = results.multi_face_landmarks[0]\n",
    "        ldmks = np.zeros((468, 3), dtype=np.float32)\n",
    "        for idx, landmark in enumerate(face_landmarks.landmark):\n",
    "            if ((landmark.HasField('visibility') and landmark.visibility < VISIBILITY_THRESHOLD)\n",
    "                    or (landmark.HasField('presence') and landmark.presence < PRESENCE_THRESHOLD)):\n",
    "                ldmks[idx, 0] = -1.0\n",
    "                ldmks[idx, 1] = -1.0\n",
    "                ldmks[idx, 2] = -1.0\n",
    "            else:\n",
    "                coords = mp_drawing._normalized_to_pixel_coordinates(\n",
    "                    landmark.x, landmark.y, width, height)\n",
    "                if coords:\n",
    "                    ldmks[idx, 0] = coords[0]\n",
    "                    ldmks[idx, 1] = coords[1]\n",
    "                    ldmks[idx, 2] = idx\n",
    "                else:\n",
    "                    ldmks[idx, 0] = -1.0\n",
    "                    ldmks[idx, 1] = -1.0\n",
    "                    ldmks[idx, 2] = -1.0\n",
    "\n",
    "    filtered_ldmks = []\n",
    "    if landmarks_list is not None:\n",
    "        for idx in landmarks_list:\n",
    "            filtered_ldmks.append(ldmks[idx])\n",
    "        filtered_ldmks = np.array(filtered_ldmks, dtype=np.float32)\n",
    "    else:\n",
    "        filtered_ldmks = ldmks\n",
    "\n",
    "    fig = px.imshow(imag)\n",
    "    for l in filtered_ldmks:\n",
    "        name = '特征_' + str(int(l[2]))\n",
    "        fig.add_trace(go.Scatter(x=(l[0],), y=(l[1],), name=name, mode='markers', \n",
    "                                marker=dict(color='red', size=5)))\n",
    "    fig.update_xaxes(range=[0,imag.shape[1]])\n",
    "    fig.update_yaxes(range=[imag.shape[0],0])\n",
    "    fig.update_layout(paper_bgcolor='#eee') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert method in available_methods, \"\\nrPPG method not recognized!!\"\n",
    "\n",
    "if cuda:\n",
    "    sig_processing.display_cuda_device()\n",
    "    sig_processing.choose_cuda_device(0)\n",
    "\n",
    "# set skin extractor\n",
    "target_device = 'GPU' if cuda else 'CPU'\n",
    "if roi_method == 'convexhull':\n",
    "    sig_processing.set_skin_extractor(\n",
    "        SkinExtractionConvexHull(target_device))\n",
    "elif roi_method == 'faceparsing':\n",
    "    sig_processing.set_skin_extractor(\n",
    "        SkinExtractionFaceParsing(target_device))\n",
    "else:\n",
    "    raise ValueError(\"Unknown 'roi_method'\")\n",
    "\n",
    "assert roi_approach == 'patches' or roi_approach=='hol', \"\\nROI extraction approach not recognized!\"\n",
    "\n",
    "# set patches\n",
    "if roi_approach == 'patches':\n",
    "    #ldmks_list = ast.literal_eval(landmarks_list)\n",
    "    #if len(ldmks_list) > 0:\n",
    "    sig_processing.set_landmarks(ldmks_list)\n",
    "    # set squares patches side dimension\n",
    "    sig_processing.set_square_patches_side(28.0)\n",
    "\n",
    "# set sig-processing and skin-processing params\n",
    "SignalProcessingParams.RGB_LOW_TH = 75\n",
    "SignalProcessingParams.RGB_HIGH_TH = 230\n",
    "SkinProcessingParams.RGB_LOW_TH = 75\n",
    "SkinProcessingParams.RGB_HIGH_TH = 230\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "# video_files = [f for f in listdir(input_path) if isfile(join(input_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_time(description, video_file_base_name,  start):\n",
    "\n",
    "    # End the timer\n",
    "    end = time.time()\n",
    "\n",
    "    # Calculate the elapsed time\n",
    "    elapsed_time = end - start\n",
    "\n",
    "    # Convert to seconds, minutes, and hours\n",
    "    seconds = int(elapsed_time % 60)\n",
    "    minutes = int((elapsed_time // 60) % 60)\n",
    "    hours = int(elapsed_time // 3600)\n",
    "\n",
    "    # Print the result in a readable format\n",
    "    print(f\"[File:{video_file_base_name}] {description}. Elapsed time: {hours} hours, {minutes} minutes, {seconds} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, pprint\n",
    "\n",
    "class RemotePPGFeatureExtractor:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def get_bbi_without_moving(self, video_file_full_name):\n",
    "        return self.get_bbi(video_file_full_name, False)\n",
    "    \n",
    "    def get_bbi(self, video_file_full_name, move_file_after_processing):\n",
    "\n",
    "        video_file_base_name = \tos.path.splitext(os.path.basename(video_file_full_name))[0]\n",
    "        target_video_file_full_name = os.path.join(target_file_path, video_file_base_name)\n",
    "        image_output_full_name = os.path.join(image_output_path, video_file_base_name + \".png\")\n",
    "        if os.path.exists(image_output_full_name):\n",
    "            print(f\"[File:{video_file_full_name}] exists. Skip\")\n",
    "            return \n",
    "        \n",
    "        #image_output_full_name = image_output_path + video_file_base_name + \".png\"\n",
    "        if verb:\n",
    "            now = datetime.now()\n",
    "            current_time = now.strftime(\"%H:%M:%S\")\n",
    "            print(\"Current Time =\", current_time)\n",
    "            # print(f'[Processing Video: ' + video_file_full_name)\n",
    "            print(f\"[File:{video_file_base_name}] Starts. Current Time: {current_time}\")\n",
    "\n",
    "        fps = get_fps(video_file_full_name)\n",
    "        sig_processing.set_total_frames(0)\n",
    "\n",
    "        # -- ROI selection\n",
    "        #檢查sig是否完成\n",
    "        sig_file_full_name = os.path.join(sig_output_path, video_file_base_name + \".pkl\")\n",
    "        sig = []\n",
    "        start = time.time()\n",
    "        if os.path.exists(sig_file_full_name) and not to_recalculate:\n",
    "            pkl_file = open(sig_file_full_name, 'rb')\n",
    "            sig = pickle.load(pkl_file)\n",
    "            pkl_file.close()\n",
    "        else:\n",
    "            try: #r_01_05\n",
    "                if roi_approach == 'hol':\n",
    "                    # SIG extraction with holistic\n",
    "                    sig = sig_processing.extract_holistic(video_file_full_name)\n",
    "                elif roi_approach == 'patches':\n",
    "                    # SIG extraction with patches\n",
    "                    sig = sig_processing.extract_patches(video_file_full_name, 'squares', 'mean')\n",
    "                # if sig != None and len(sig)>0:\n",
    "                if len(sig)>0:\n",
    "                    output = open(sig_file_full_name, 'wb')\n",
    "                    pickle.dump(sig, output)\n",
    "                    output.close()\n",
    "                # else:\n",
    "                #     print(f\"error r_01_06: No result generated for {video_file_full_name}\")\n",
    "                #     return\n",
    "            except Exception as inst:\n",
    "                print(f\"error r_01_05:{sig_file_full_name}\")\n",
    "                print(inst)\n",
    "                return\n",
    "\n",
    "        # end = time.time()\n",
    "        # time_span = end - start\n",
    "        # print(\"Signal extraction completed. Landmark type is \"+ ldmks_list_choice + \". Time span= \"  + str(time_span))\n",
    "        print_time(\"Signal extraction completed. Landmark type is \"+ ldmks_list_choice, video_file_base_name , start)\n",
    "        # -- sig windowing\n",
    "        #len(sig)/fps\n",
    "\n",
    "        #用6秒分割，再去计算心率，\n",
    "        windowed_sig, timesES = sig_windowing(sig, length_of_windows , 1, fps)\n",
    "        print_time(f\"Video segmentation completed\", video_file_base_name , start)\n",
    "        #如果不算心率變異, 下面這行可以取回全部\n",
    "        #windowed_sig, timesES = sig_windowing(sig, np.floor(len(sig)/fps), np.floor(len(sig)/fps), fps)\n",
    "\n",
    "        # -- PRE FILTERING\n",
    "        filtered_windowed_sig = windowed_sig\n",
    "\n",
    "        # -- color threshold - applied only with patches\n",
    "        if roi_approach == 'patches':\n",
    "            filtered_windowed_sig = apply_filter(windowed_sig,\n",
    "                                                    rgb_filter_th,\n",
    "                                                    params={'RGB_LOW_TH':  75,\n",
    "                                                            'RGB_HIGH_TH': 230})\n",
    "            print_time(f\"Windows filtered completed\", video_file_base_name , start)\n",
    "\n",
    "        # -- BVP Extraction\n",
    "        module = import_module('pyVHR.BVP.methods')\n",
    "        method_to_call = getattr(module, method)\n",
    "        if 'cpu' in method:\n",
    "            method_device = 'cpu'\n",
    "        elif 'torch' in method:\n",
    "            method_device = 'torch'\n",
    "        elif 'cupy' in method:\n",
    "            method_device = 'cuda'\n",
    "\n",
    "        if 'POS' in method:\n",
    "            pars = {'fps':'adaptive'}\n",
    "        elif 'PCA' in method or 'ICA' in method:\n",
    "            pars = {'component': 'all_comp'}\n",
    "        else:\n",
    "            pars = {}\n",
    "            #\n",
    "\n",
    "\n",
    "        bvps_file_full_name = os.path.join(bvps_output_path, video_file_base_name + \".pkl\")\n",
    "        #bvps_file_full_name = bvps_output_path + video_file_base_name + \".pkl\"\n",
    "        if os.path.exists(bvps_file_full_name) and not to_recalculate:\n",
    "            pkl_file = open(bvps_file_full_name, 'rb')\n",
    "            bvps = pickle.load(pkl_file)\n",
    "            pkl_file.close()\n",
    "            print_time(\"BVPS loaded.\", video_file_base_name , start)\n",
    "        else:\n",
    "            try: #r_01_02\n",
    "                # Transform an input RGB windowed signal in a BVP windowed signal using a rPPG method (see pyVHR.BVP.methods).\n",
    "                bvps = RGB_sig_to_BVP(filtered_windowed_sig, fps,\n",
    "                                        device_type=method_device, method=method_to_call, params=pars)            \n",
    "                end = time.time()\n",
    "                time_span = end - start\n",
    "                print(time_span)\n",
    "                output = open(bvps_file_full_name, 'wb')\n",
    "                pickle.dump(bvps, output)\n",
    "                output.close()\n",
    "                print_time(f\"Signal to BVP completed\", video_file_base_name , start)\n",
    "            except Exception as inst:\n",
    "                print(\"error r_01_02\")\n",
    "                print(inst) \n",
    "                return\n",
    "\n",
    "        # end = time.time()\n",
    "        # time_span = end - start\n",
    "        # print(f\"Signal to BVP completed:{video_file_base_name}. Time span:{time_span}\")\n",
    "        \n",
    "\n",
    "        # -- POST FILTERING\n",
    "        if post_filt:\n",
    "            try: #r_01_03\n",
    "                module = import_module('pyVHR.BVP.filters')\n",
    "                method_to_call = getattr(module, 'BPfilter')\n",
    "                bvps = apply_filter(bvps, \n",
    "                                    method_to_call, \n",
    "                                    fps=fps, \n",
    "                                    params={'minHz':0.65, 'maxHz':4.0, 'fps':'adaptive', 'order':6})\n",
    "                print_time(f\"Post filter completed\", video_file_base_name , start)\n",
    "            except Exception as inst:\n",
    "                print(\"error r_01_03\")\n",
    "                print(inst) \n",
    "                return \n",
    "\n",
    "        if bpm_type == 'welch':\n",
    "            if cuda:\n",
    "                bpmES = BVP_to_BPM_cuda(bvps, fps, minHz=0.65, maxHz=4.0)\n",
    "            else:\n",
    "                bpmES = BVP_to_BPM(bvps, fps, minHz=0.65, maxHz=4.0)\n",
    "            \n",
    "        elif bpm_type == 'psd_clustering':\n",
    "            if cuda:\n",
    "                bpmES = BVP_to_BPM_PSD_clustering_cuda(bvps, fps, minHz=0.65, maxHz=4.0)\n",
    "            else:\n",
    "                bpmES = BVP_to_BPM_PSD_clustering(bvps, fps, minHz=0.65, maxHz=4.0)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown 'bpm_type'\")\n",
    "        print_time(\"BVP to BPM completed\", video_file_base_name , start)\n",
    "        \n",
    "        # median BPM from multiple estimators BPM\n",
    "        median_bpmES, mad_bpmES = multi_est_BPM_median(bpmES)\n",
    "        #print(f\"Get median and mad completed:{video_file_base_name}.\")\n",
    "        print_time(f\"Get median and mad completed.\", video_file_base_name , start)\n",
    "\n",
    "        import pandas as pd\n",
    "        bpm_results = pd.DataFrame(\n",
    "        {'time': timesES,\n",
    "        'median': median_bpmES,\n",
    "        'mad': mad_bpmES\n",
    "        })\n",
    "\n",
    "        \n",
    "        plt.title(video_file_base_name)\n",
    "        #plt.figure()\n",
    "        plt.plot(timesES, median_bpmES)\n",
    "        plt.fill_between(timesES, median_bpmES-mad_bpmES, median_bpmES+mad_bpmES, alpha=0.2)\n",
    "        plt.savefig(image_output_full_name)\n",
    "        fig1 = plt.figure(video_file_base_name)\n",
    "\n",
    "        bpmES_file_full_name = os.path.join(bpmES_output_path, video_file_base_name + \".csv\")\n",
    "        #bpmES_file_full_name = bpmES_output_path + video_file_base_name + \".csv\"\n",
    "        try:\n",
    "            bpmES_frame = pd.DataFrame(bpmES) \n",
    "            np.savetxt(bpmES_file_full_name,bpmES_frame,delimiter=\",\")\n",
    "        except Exception as inst:\n",
    "            print(\"error r_01_07\")\n",
    "            print(inst) \n",
    "        bpm_file_full_name = os.path.join(bpm_output_path, video_file_base_name + \".csv\")\n",
    "        #bpm_file_full_name = bpm_output_path + video_file_base_name + \".csv\"\n",
    "        np.savetxt(bpm_file_full_name,bpm_results,delimiter=\",\")\n",
    "\n",
    "        if move_file_after_processing:\n",
    "            shutil.move(video_file_full_name, target_video_file_full_name)\n",
    "\n",
    "        # end = time.time()\n",
    "        # time_span = end - start\n",
    "        # print(f\"All processes completed:{video_file_base_name}. Time span:{time_span}\")\n",
    "        print_time(f\"All processes completed.\", video_file_base_name , start)\n",
    "        return bpm_results\n",
    "\n",
    "    # def process_videos(self, video_files, move_file_after_processing):\n",
    "\n",
    "    #     for ind, video_file_name in enumerate(video_files, 1):\n",
    "    #         self.process_video(video_file_name, move_file_after_processing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Video to BBI Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_ppg_extractor = RemotePPGFeatureExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remote_ppg_extractor.get_bbi(testing_video_file,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folder to BBI Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_analysis = utilities.SingleModalityAnalysis()\n",
    "\n",
    "# base_directory = r\"D:\\Programming3\\psychai\\example\\paper5_mmer_moral\\resources\\raw_data\"\n",
    "# base_directory = r\"K:\\Backup\\Experiments\\Moral Elevation\\Disk1_2_combined\\FS-9 Day 1\"\n",
    "base_directory = r\"G:\\Experiments\\Moral Elevation\\Disk1_2_combined\\FS-9 Day 1\"\n",
    "\n",
    "filters = [(2, '23')]\n",
    "user_ids = range(1,120)\n",
    "merging_pdf = pd.read_csv('../resources/data/rct/rct.csv')\n",
    "\n",
    "df_largest = single_analysis.prosss_folder(base_directory, filters, user_ids, merging_pdf, modality_value=\"RecordedVideo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_largest.iloc[[0]][\"files\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remote_ppg_extractor.get_bbi_without_moving(df_largest.iloc[[0]][\"files\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for files_row in df_largest[\"files\"]:\n",
    "#     remote_ppg_extractor.get_bbi_without_moving(files_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    # Submit tasks to the thread pool for each item (file or data identifier)\n",
    "    futures = {executor.submit(remote_ppg_extractor.get_bbi_without_moving, item): item for item in df_largest[\"files\"]}\n",
    "    \n",
    "    # Track the progress using tqdm, and collect results as they are completed\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Extracting features\"):\n",
    "        try:\n",
    "            result_series = future.result()\n",
    "            result_df = result_series.to_frame().T\n",
    "            df_results = pd.concat([df_results, result_df], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing item {futures[future]}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 附錄\n",
    "- 版權：Ivan Liu 最後更新時間 2024\n",
    "- 虛擬環境：course_12\n",
    "- 內容來源（本教學的部分內容改編自）\n",
    "\n",
    "    #这个内容是来自github pyVHR https://github.com/phuselab/pyVHR\n",
    "\n",
    "    #安装时用conda可以把dependency载下来\n",
    "\n",
    "    #conda env create --file https://raw.githubusercontent.com/phuselab/pyVHR/master/pyVHR_env.yml\n",
    "\n",
    "    #最后再安装pip install pyvhr\n",
    "    \n",
    "- 參考文獻 \n",
    "    - \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psychai241104",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
